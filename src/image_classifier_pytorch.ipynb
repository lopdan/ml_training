{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "d2l.use_svg_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=False, transform=trans, download=True)\n",
    "\n",
    "def get_dataloader_workers(): #@save\n",
    "    \"\"\"Use 4 processes to read the data.\"\"\"\n",
    "    return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None): #@save\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=trans, download=True\n",
    "    )\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=trans, download=True\n",
    "    )\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloader_workers()),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=get_dataloader_workers()))\n",
    "\n",
    "# (60000, 10000) shape of the training/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    \"\"\"Return labels and convert to numeric.\"\"\"\n",
    "    text_labels = [\n",
    "        't-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "        'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'\n",
    "    ]\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1): #@save\n",
    "    \"\"\"Plot list of images.\n",
    "\n",
    "    Args:\n",
    "        imgs (Tensor): images of the dataset.\n",
    "        num_rows (int): number of rows to plot.\n",
    "        num_cols (int): number of columns to plot.\n",
    "        titles (string, optional): label from image. Defaults to None.\n",
    "        scale (float, optional): size to scale image. Defaults to 1.5.\n",
    "\n",
    "    Returns:\n",
    "        .axes.Axes: array of axes.\n",
    "    \"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    figure, axes = d2l.plt.subplots(num_rows, num_cols, squeeze=False, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # Tensor Image\n",
    "            ax.imshow(img.numpy())\n",
    "        else:\n",
    "            # PIL Image\n",
    "            ax.imshow(img)\n",
    "            ax.axes.get_xaxis().set_visible(False)\n",
    "            ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "\n",
    "    figure.subplots_adjust(left=0.5,\n",
    "                    bottom=0.5, \n",
    "                    right=1.5, \n",
    "                    top=1.5, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = load_data_fashion_mnist(32, resize=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/github/ml_training/src/image_classifier_pytorch.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/github/ml_training/src/image_classifier_pytorch.ipynb#ch0000004?line=0'>1</a>\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(data\u001b[39m.\u001b[39;49mDataLoader(train_iter, batch_size\u001b[39m=\u001b[39;49m\u001b[39m18\u001b[39;49m)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/github/ml_training/src/image_classifier_pytorch.ipynb#ch0000004?line=1'>2</a>\u001b[0m show_images(X\u001b[39m.\u001b[39mreshape(\u001b[39m18\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m), \u001b[39m2\u001b[39m, \u001b[39m9\u001b[39m, titles\u001b[39m=\u001b[39mget_fashion_mnist_labels(y))\n",
      "File \u001b[0;32m~/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=648'>649</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=649'>650</a>\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=650'>651</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=651'>652</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=652'>653</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=653'>654</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=654'>655</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=655'>656</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=689'>690</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=690'>691</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=691'>692</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=692'>693</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=693'>694</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/lopdan/anaconda3/envs/py386/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))\n",
    "show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90e55b616c63168a6db6e336c7d9244a5e55794970d67bc6e4d9ec580cecf191"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('py386')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
